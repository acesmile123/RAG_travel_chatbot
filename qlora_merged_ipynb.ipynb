{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install unsloth transformers torch unsloth_zoo bitsandbytes trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:17:00.309776Z",
     "iopub.status.busy": "2026-01-16T04:17:00.308951Z",
     "iopub.status.idle": "2026-01-16T04:17:01.969511Z",
     "shell.execute_reply": "2026-01-16T04:17:01.968666Z",
     "shell.execute_reply.started": "2026-01-16T04:17:00.309718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T04:17:59.152637Z",
     "iopub.status.busy": "2026-01-16T04:17:59.152316Z",
     "iopub.status.idle": "2026-01-16T04:30:19.933813Z",
     "shell.execute_reply": "2026-01-16T04:30:19.933006Z",
     "shell.execute_reply.started": "2026-01-16T04:17:59.152604Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Loading Adapter & Base Model tá»«: acesmile/Qwen3_QloRA...\n",
      "==((====))==  Unsloth 2026.1.3: Fast Qwen3 patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa38180a9bd4b6a9209ac97835af1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Äang Merge LoRA vÃ o Base Model (Ra dáº¡ng 16-bit)...\n",
      "Unsloth: Saving to acesmile/Qwen3_QLoRA_AWQ will fail, but using a temp folder works! Switching to a temp folder then uploading!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfc4d32df9d4ac7b799bc96f593aef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7086314f47048319a5fc6c9ad2fc8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417b5aca2c624772a9efd36a4223beb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00006.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5efc417c4f74d61a4d50aa82bab66a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00006.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  17%|â–ˆâ–‹        | 1/6 [00:16<01:21, 16.24s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb4ca43d6ff45c5b3e9e9219f09b399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00006.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:35<01:12, 18.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2e444a290c4e62adcaa89202b52b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00006.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:55<00:56, 18.97s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe342e3ce2e64b73a825f3e382d062fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00006.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [01:15<00:38, 19.40s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038480da7c754129988ae93876295303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00006.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [01:34<00:19, 19.08s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2581b3552d5c4a42940c11fc85287b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00006.safetensors:   0%|          | 0.00/4.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [01:52<00:00, 18.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8407757f9a8347119e3c4b894c378530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97efdfbaecfa4882a0137fa2db8adbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:  17%|â–ˆâ–‹        | 1/6 [01:40<08:24, 100.86s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d7350c07e04836af497350cab481e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9905b83606e1474db08c0cec4b2bef34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [03:31<07:05, 106.45s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dce2a1aaf84d1dbdbed12794af3af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86a045fcb1041b7b89a6239ee8ecdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [05:12<05:12, 104.17s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f696c091074d7e9bc949096676ac27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695ec8649f4642609d09c3f28ffa5afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [06:54<03:26, 103.22s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f77a210a8c42ee9a922c17eb67bca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337b936676e4415da4689542bb9813eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [08:34<01:42, 102.21s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ceba2b8ac754ac5a87018f0bd3c42ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2881da21d24e6ea7e280504d20f78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [10:03<00:00, 100.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/tmp/tmpg05zr2pr`\n",
      "âœ… [OK] ÄÃ£ merge xong! Model náº±m táº¡i folder: qwen3-14b-merged-fp16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer\n",
    "from config import HF_TOKEN\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "\n",
    "ADAPTER_REPO = \"acesmile/Qwen3_QloRA\" \n",
    "MERGED_REPO   = \"acesmile/Qwen3-14B_merged\"\n",
    "MAX_SEQ_LEN  = 4096\n",
    "\n",
    "def merge_lora_to_full():\n",
    "    print(f\"ðŸ”§ Loading Adapter & Base Model tá»«: {ADAPTER_REPO}...\")\n",
    "    \n",
    "    \n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = ADAPTER_REPO, \n",
    "        max_seq_length = MAX_SEQ_LEN,\n",
    "        dtype = torch.float16,        \n",
    "        load_in_4bit = True,  \n",
    "    )\n",
    "\n",
    "    \n",
    "    FastLanguageModel.for_inference(model)\n",
    "\n",
    "    print(\"ðŸ’¾ Äang Merge LoRA vÃ o Base Model (Ra dáº¡ng 16-bit)...\")\n",
    " \n",
    "    model.push_to_hub_merged(\n",
    "        \"acesmile/Qwen3_QLoRA_AWQ\",\n",
    "        tokenizer,\n",
    "        save_method = \"merged_16bit\", \n",
    "        private = False,\n",
    "        token = HF_TOKEN,\n",
    "    )\n",
    "\n",
    "    print(f\"âœ… [OK] ÄÃ£ merge xong! Model náº±m táº¡i folder: {MERGED_REPO}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_lora_to_full()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
