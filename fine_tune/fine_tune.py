import pandas as pd
import json
import time
import os
import re
import requests

# ============= C·∫§U H√åNH =============
INPUT_FILE = 'fine_tune1.csv'
OUTPUT_FILE = 'training_data_safe.jsonl'
NUM_VARIANTS = 5  # Gi·∫£m xu·ªëng 5 ƒë·ªÉ nhanh v√† an to√†n h∆°n
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "llama3.2:3b"

SYSTEM_PROMPT = """B·∫°n l√† tr·ª£ l√Ω du l·ªãch chuy√™n nghi·ªáp, am hi·ªÉu s√¢u s·∫Øc v·ªÅ du l·ªãch Vi·ªát Nam, ƒë·∫∑c bi·ªát l√† 6 t·ªânh/th√†nh: H√† N·ªôi, ƒê√† N·∫µng, H·ªì Ch√≠ Minh, Qu·∫£ng Ninh, T√¢y Ninh v√† ƒê√† L·∫°t. 
H√£y tr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán, ch√≠nh x√°c, chi ti·∫øt v·ªõi ƒë·ªãa ch·ªâ c·ª• th·ªÉ v√† nhi·ªát t√¨nh. S·ª≠ d·ª•ng emoji ph√π h·ª£p üáªüá≥üèñÔ∏èüç≤‚òïüèûÔ∏è."""

def test_ollama():
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            print(f"Ollama ƒëang ch·∫°y.")
            return True
        return False
    except:
        print("ERROR: Ollama ch∆∞a b·∫≠t!")
        return False

def extract_location(text):
    """Tr√≠ch xu·∫•t t√™n ƒë·ªãa danh t·ª´ c√¢u h·ªèi"""
    locations = ['H√† N·ªôi', 'ƒê√† N·∫µng', 'H·ªì Ch√≠ Minh', 'S√†i G√≤n', 'Qu·∫£ng Ninh', 
                 'H·∫° Long', 'T√¢y Ninh', 'ƒê√† L·∫°t']
    for loc in locations:
        if loc in text:
            return loc
    return None

def generate_variants_safe(question):
    """
    Gen bi·∫øn th·ªÉ AN TO√ÄN - KH√îNG CHO PH√âP thay ƒë·ªïi ƒë·ªãa danh
    """
    location = extract_location(question)
    
    prompt = f"""B·∫°n l√† chuy√™n gia vi·∫øt l·∫°i c√¢u h·ªèi du l·ªãch. H√£y vi·∫øt l·∫°i c√¢u sau th√†nh {NUM_VARIANTS} c√°ch kh√°c nhau.

C√¢u g·ªëc: "{question}"

 QUY T·∫ÆC NGHI√äM NG·∫∂T - PH·∫¢I TU√ÇN TH·ª¶:
1. TUY·ªÜT ƒê·ªêI KH√îNG ƒê∆Ø·ª¢C thay ƒë·ªïi ho·∫∑c th√™m t√™n ƒë·ªãa ƒëi·ªÉm/t·ªânh th√†nh kh√°c
2. B·∫ÆT BU·ªòC gi·ªØ nguy√™n 100% t√™n ƒë·ªãa danh c√≥ trong c√¢u g·ªëc
3.  Ch·ªâ ƒë∆∞·ª£c thay ƒë·ªïi: c√°ch h·ªèi, t·ª´ ng·ªØ, phong c√°ch (Gen Z/trang tr·ªçng/ng·∫Øn g·ªçn)
4.  ƒêa d·∫°ng phong c√°ch: "Cho m√¨nh h·ªèi...", "B·∫°n ∆°i...", "Anh ch·ªã t∆∞ v·∫•n...", "...·∫°", "...nh·ªÉ", "...v·∫≠y?"
5.  D√πng t·ª´ ƒë·ªãa ph∆∞∆°ng: gh√©, check-in, chill, x·ªãn, chu·∫©n, ƒë·ªânh, ngon
6.  KH√îNG th√™m ƒë·ªãa danh m·ªõi nh∆∞ "·ªû ƒê√† N·∫µng", "T·∫°i H√† N·ªôi" n·∫øu c√¢u g·ªëc kh√¥ng c√≥
7.  Ch·ªâ tr·∫£ v·ªÅ danh s√°ch c√¢u h·ªèi, m·ªói c√¢u 1 d√≤ng, KH√îNG ƒë√°nh s·ªë, KH√îNG gi·∫£i th√≠ch

V√ç D·ª§:
- C√¢u g·ªëc: "·ªû H√† N·ªôi cafe tr·ª©ng qu√°n n√†o ngon?"
-  ƒê√öNG: "Cafe tr·ª©ng H√† N·ªôi ch·ªó n√†o ƒë·ªânh?"
-  ƒê√öNG: "Cho m√¨nh h·ªèi qu√°n cafe tr·ª©ng ngon t·∫°i H√† N·ªôi ·∫°"
-  SAI: "·ªû ƒê√† N·∫µng cafe tr·ª©ng qu√°n n√†o ngon?" (thay ƒë·ªïi ƒë·ªãa danh)
-  SAI: "Cafe tr·ª©ng Qu·∫£ng Ninh..." (th√™m ƒë·ªãa danh m·ªõi)

Danh s√°ch {NUM_VARIANTS} c√¢u h·ªèi:"""

    try:
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.5,  # Gi·∫£m t·ª´ 0.8 ‚Üí 0.5 ƒë·ªÉ √≠t s√°ng t·∫°o h∆°n
                    "top_p": 0.85,
                    "num_predict": 150  # Gi·ªõi h·∫°n tokens
                }
            },
            timeout=30
        )
        if response.status_code == 200:
            result = response.json()
            text = result.get('response', '')
            lines = [l.strip() for l in text.split('\n') if len(l.strip()) > 10]
            
            # X·ª≠ l√Ω s·∫°ch output
            cleaned = []
            for line in lines:
                # B·ªè qua l·ªùi gi·ªõi thi·ªáu
                if any(x in line.lower() for x in ["d∆∞·ªõi ƒë√¢y", "danh s√°ch", "c√°ch vi·∫øt", "v√≠ d·ª•"]):
                    continue
                
                # X√≥a nh√£n phong c√°ch v√† s·ªë th·ª© t·ª±
                line = re.sub(r'^(C√¢u|Phong c√°ch|Ki·ªÉu)\s+[\w\s]+:\s*', '', line, flags=re.IGNORECASE)
                line = re.sub(r'^[\-\*\d\.\)\s]+', '', line).strip()
                
                # VALIDATE: Ki·ªÉm tra ƒë·ªãa danh c√≥ ƒë√∫ng kh√¥ng
                if location and location not in line:
                    continue  # B·ªè qua c√¢u kh√¥ng c√≥ ƒë·ªãa danh g·ªëc
                
                # Ki·ªÉm tra kh√¥ng c√≥ ƒë·ªãa danh l·∫°
                other_locations = [loc for loc in ['H√† N·ªôi', 'ƒê√† N·∫µng', 'H·ªì Ch√≠ Minh', 
                                                    'Qu·∫£ng Ninh', 'T√¢y Ninh', 'ƒê√† L·∫°t'] 
                                   if loc != location]
                if any(other_loc in line for other_loc in other_locations):
                    continue  # B·ªè qua c√¢u c√≥ ƒë·ªãa danh l·∫°
                
                if len(line) > 15:
                    cleaned.append(line)
            
            return cleaned[:NUM_VARIANTS]
        return None
    except Exception as e:
        print(f" L·ªói API: {str(e)[:50]}")
        return None

def main():
    print("\n" + "="*70)
    print(" GEN DATA AN TO√ÄN - VALIDATE CH·∫∂T CH·∫º ƒê·ªäA DANH")
    print("   Ngu·ªìn: fine_tune1.csv ‚Üí training_data_safe.jsonl")
    print("="*70 + "\n")
    
    if not test_ollama(): return

    processed_answers = set()
    if os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line)
                    processed_answers.add(data['messages'][2]['content'])
                except: continue
        print(f" ƒê√£ ho√†n th√†nh {len(processed_answers)} m·∫´u. ƒêang ch·∫°y ti·∫øp...\n")

    df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig').dropna(subset=['Question', 'Answer'])
    total = len(df)
    success_count = 0
    fail_count = 0
    
    with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:
        for idx, row in df.iterrows():
            q_raw = str(row['Question']).strip()
            ans = str(row['Answer']).strip()
            
            if ans in processed_answers: continue

            print(f" [{idx+1}/{total}] {q_raw[:50]}...")
            
            variants = generate_variants_safe(q_raw)
            
            if variants and len(variants) >= 3:  # Ch·∫•p nh·∫≠n t·ª´ 3 c√¢u tr·ªü l√™n
                for v in variants:
                    entry = {
                        "messages": [
                            {"role": "system", "content": SYSTEM_PROMPT},
                            {"role": "user", "content": v},
                            {"role": "assistant", "content": ans}
                        ]
                    }
                    f.write(json.dumps(entry, ensure_ascii=False) + '\n')
                f.flush()
                success_count += 1
                print(f"   OK: {len(variants)} bi·∫øn th·ªÉ")
            else:
                # Fallback: D√πng c√¢u g·ªëc
                entry = {
                    "messages": [
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": q_raw},
                        {"role": "assistant", "content": ans}
                    ]
                }
                f.write(json.dumps(entry, ensure_ascii=False) + '\n')
                fail_count += 1
                print(f"   D√πng g·ªëc (AI l·ªói ho·∫∑c validate fail)")
            
            time.sleep(0.1)

    print("\n" + "="*70)
    print(f" HO√ÄN TH√ÄNH!")
    print(f"   Th√†nh c√¥ng: {success_count} | D√πng g·ªëc: {fail_count}")
    print(f"   File: {OUTPUT_FILE}")
    print("="*70)

if __name__ == "__main__":
    main()
