import pandas as pd
import json
import time
import os
import re
import requests

# ============= C·∫§U H√åNH =============
INPUT_FILE = 'fine_tune1.csv'
OUTPUT_FILE = 'training_data_ollama.jsonl'
NUM_VARIANTS = 10
OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "llama3.2:3b" # Ho·∫∑c qwen2.5:7b ƒë·ªÉ ti·∫øng Vi·ªát chu·∫©n h∆°n

# SYSTEM_PROMPT m·ªõi cho quy m√¥ to√†n Vi·ªát Nam
SYSTEM_PROMPT = """B·∫°n l√† tr·ª£ l√Ω du l·ªãch th√¥ng minh, am hi·ªÉu s√¢u s·∫Øc v·ªÅ du l·ªãch Vi·ªát Nam. 
H√£y tr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán, ch√≠nh x√°c v√† nhi·ªát t√¨nh. S·ª≠ d·ª•ng emoji ph√π h·ª£p üáªüá≥üèñÔ∏èüç≤."""

def test_ollama():
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            print(f" Ollama ƒëang ch·∫°y.")
            return True
        return False
    except:
        print(" ERROR: Ollama ch∆∞a b·∫≠t!")
        return False

def generate_variants_with_ollama(question):
    """
    Prompt ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ t·∫°o bi·∫øn th·ªÉ c√¢u h·ªèi du l·ªãch Vi·ªát Nam t·ª± nhi√™n v√† ƒëa d·∫°ng
    """
    prompt = f"""B·∫°n l√† chuy√™n gia ng√¥n ng·ªØ du l·ªãch Vi·ªát Nam. H√£y vi·∫øt l·∫°i c√¢u h·ªèi sau th√†nh {NUM_VARIANTS} c√°ch kh√°c nhau.

C√¢u g·ªëc: "{question}"

Y√äU C·∫¶U NGHI√äM NG·∫∂T:
1. Gi·ªØ nguy√™n n·ªôi dung v√† ƒë·ªãa danh ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn trong c√¢u g·ªëc.
2. ƒêa d·∫°ng phong c√°ch: Gen Z (slay, nh·ª©c n√°ch), h·ªèi ng·∫Øn g·ªçn, trang tr·ªçng l·ªãch s·ª±, h·ªèi t∆∞ v·∫•n chi ti·∫øt.
3. Thay ƒë·ªïi c√°ch di·ªÖn ƒë·∫°t nh∆∞ng v·∫´n gi·ªØ √Ω nghƒ©a: thay t·ª´ ƒë·ªìng nghƒ©a, ƒë·∫£o th·ª© t·ª±, th√™m c·∫£m x√∫c.
4. T·ª∂ L·ªÜ:
   - 5 c√¢u ph·∫£i c√≥ t√™n T·ªânh/Th√†nh ph·ªë r√µ r√†ng (H√† N·ªôi, ƒê√† N·∫µng, H·ªì Ch√≠ Minh, Qu·∫£ng Ninh, T√¢y Ninh, ƒê√† L·∫°t).
   - 5 c√¢u ch·ªâ d√πng t√™n ƒë·ªãa danh c·ª• th·ªÉ (LƒÉng B√°c, C·∫ßu V√†ng, M·ªπ Kh√™, ph·ªë Nguy·ªÖn Hu·ªá, B√† N√†...) m√† kh√¥ng c·∫ßn nh·∫Øc t√™n t·ªânh.
5. S·ª≠ d·ª•ng t·ª´ ƒë·ªãa ph∆∞∆°ng t·ª± nhi√™n: gh√©, chill, check-in, x·ªãn, chu·∫©n, ƒë·ªânh, nh·ª©c n√°ch...
6. Ch·ªâ tr·∫£ v·ªÅ danh s√°ch c√¢u h·ªèi, m·ªói c√¢u 1 d√≤ng, KH√îNG ƒë√°nh s·ªë, KH√îNG gi·∫£i th√≠ch.

Danh s√°ch c√¢u h·ªèi:"""

    try:
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": 0.8, "top_p": 0.9}
            },
            timeout=60
        )
        if response.status_code == 200:
            result = response.json()
            text = result.get('response', '')
            lines = [l.strip() for l in text.split('\n') if len(l.strip()) > 5]
            
            # X·ª¨ L√ù S·∫†CH OUTPUT NGAY T·∫†I ƒê√ÇY (t∆∞∆°ng t·ª± clean.py)
            cleaned = []
            for line in lines:
                # B·ªè qua l·ªùi gi·ªõi thi·ªáu c·ªßa AI
                if "D∆∞·ªõi ƒë√¢y l√†" in line or "c√°ch vi·∫øt l·∫°i" in line or "danh s√°ch" in line.lower():
                    continue
                
                # X√≥a nh√£n phong c√°ch: "C√¢u Gen Z:", "Phong c√°ch..."
                line = re.sub(r'^(C√¢u|Phong c√°ch|Ki·ªÉu)\s+[\w\s]+:\s*', '', line, flags=re.IGNORECASE)
                
                # X√≥a s·ªë th·ª© t·ª±, d·∫•u g·∫°ch ƒë·∫ßu d√≤ng, d·∫•u sao
                line = re.sub(r'^[\-\*\d\.\)\s]+', '', line).strip()
                
                # Ch·ªâ l∆∞u c√¢u c√≥ ƒë·ªô d√†i h·ª£p l√Ω
                if len(line) > 10:  # TƒÉng t·ª´ 5 l√™n 10 ƒë·ªÉ l·ªçc ch·∫∑t h∆°n
                    cleaned.append(line)
            
            return cleaned[:NUM_VARIANTS]
        return None
    except Exception as e:
        print(f"  L·ªói API: {str(e)[:50]}")
        return None

def main():
    print("\n" + "="*70)
    print("GEN DATA DU L·ªäCH VI·ªÜT NAM (6 T·ªàNH: H√Ä N·ªòI, ƒê√Ä N·∫¥NG, HCM, QU·∫¢NG NINH, T√ÇY NINH, ƒê√Ä L·∫†T)")
    print("   Ngu·ªìn: fine_tune1.csv -> training_data_ollama.jsonl")
    print("="*70 + "\n")
    
    if not test_ollama(): return

    processed_answers = set()
    if os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line)
                    processed_answers.add(data['messages'][2]['content'])
                except: continue
        print(f"ƒê√£ ho√†n th√†nh {len(processed_answers)} m·∫´u. ƒêang ch·∫°y ti·∫øp...\n")

    df = pd.read_csv(INPUT_FILE, encoding='utf-8-sig').dropna(subset=['Question', 'Answer'])
    total = len(df)
    
    with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:
        for idx, row in df.iterrows():
            q_raw = str(row['Question']).strip()
            ans = str(row['Answer']).strip()
            
            if ans in processed_answers: continue

            print(f"[{idx+1}/{total}] ƒêang x·ª≠ l√Ω c√¢u h·ªèi v·ªÅ: {q_raw[:50]}...")
            
            variants = generate_variants_with_ollama(q_raw)
            
            if variants and len(variants) >= 5:
                for v in variants:
                    entry = {
                        "messages": [
                            {"role": "system", "content": SYSTEM_PROMPT},
                            {"role": "user", "content": v},
                            {"role": "assistant", "content": ans}
                        ]
                    }
                    f.write(json.dumps(entry, ensure_ascii=False) + '\n')
                f.flush()
                print(f"   OK: ƒê√£ th√™m {len(variants)} bi·∫øn th·ªÉ.")
            else:
                # Fallback n·∫øu AI l·ªói: D√πng c√¢u g·ªëc v√† th√™m bi·∫øn th·ªÉ ƒë∆°n gi·∫£n
                for template in [q_raw, f"B·∫°n t∆∞ v·∫•n gi√∫p m√¨nh: {q_raw}", f"Cho m√¨nh h·ªèi v·ªÅ: {q_raw}"]:
                    entry = {
                        "messages": [
                            {"role": "system", "content": SYSTEM_PROMPT},
                            {"role": "user", "content": template},
                            {"role": "assistant", "content": ans}
                        ]
                    }
                    f.write(json.dumps(entry, ensure_ascii=False) + '\n')
                print(f"   AI l·ªói: ƒê√£ d√πng c√¢u g·ªëc + bi·∫øn th·ªÉ ƒë∆°n gi·∫£n l√†m d·ª± ph√≤ng.")
            
            time.sleep(0.3) # Local n√™n ch·∫°y r·∫•t nhanh

    print("\n" + "="*70)
    print(f"HO√ÄN TH√ÄNH! File: {OUTPUT_FILE}")
    print("="*70)

if __name__ == "__main__":
    main()
