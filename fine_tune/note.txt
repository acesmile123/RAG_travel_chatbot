
====###====
Fine tune

Fine-tuning
Là quá trình huấn luyện lại (đào tạo thêm) cho mô hình AI gốc (như GPT-3.5, Llama).

Mình chuẩn bị hàng ngàn cặp câu hỏi - trả lời mẫu (Dataset).

Mình nạp vào mô hình để điều chỉnh các trọng số (weights) bên trong não bộ của nó.

Kết quả: Mô hình thay đổi cách hành văn, học được các kiến thức đặc thù sâu trong nơ-ron thần kinh.



====###====
Tạo dữ liệu câu hỏi - trả lời chuẩn ban đầu bằng gemini
Tạo được 100 câu (trong file fine_tune.csv)

Và 100 câu đó được dùng làm "seed" -> sinh ra các thể loại câu mới, biến thể từ đó 
(từ 1 ý hỏi mà ta có thể sinh ra được 10 cách hỏi và trả lời khác nhau chẳng hạn)

output cuối cùng mà em có đề xuất hôm bữa là định dạng file jsonl với cấu trúc:
System - user - assistant
để nạp vào model

====###====
Mục tiêu việc làm fine tune:
Mục tiêu của task này là tạo bộ dữ liệu Fine-tune để dạy Bot 'Phong cách trả lời chuyên 
nghiệp', chứ không phải dạy Bot học thuộc lòng dữ liệu (phần dữ liệu đã có RAG lo)

Thông tin được lấy mô phỏng cuộc trò chuyện về chủ đề Đà Lạt
Vậy thông tin cần chính xác ngay từ bước này không? Có và không 

    Vì: Fine tune là quá trình mình đào tạo khả năng trả lời phù hợp
        và chuyên nghiệp -> mục tiêu dạy cho cách trả lời
            ví dụ giá vé mình có thể dữ liệu bị lệch so với thực tế cũng được

    Tuy nhiên: không được sai kiến thức nền tảng
            ví dụ Đà Lạt có biển -> hỏng trọng số

        - ở khâu train model, nếu mình có thể xử lý được sai số nhỏ 
        như giá vé mình dạy 160k nhưng thực tế thì RAG có độ ưu tiên cao hơn
        nên nó sẽ ưu tiên trả lời 250k theo RAG

        - Còn nếu dạy sai, trọng số sẽ lệch hoặc mất, dù thông tin RAG 
        đưa thông tin đúng, Model vẫn có thể bị ngáo và trả lời lúc Đà Lạt,
        lúc miền Bắc, lúc Hồ Chí Minh....


====###====
Vậy dữ liệu fine-tune có cần phải bao hết thông tin các tỉnh mà mình làm không?
    -> không cần thiết

    Mình tập trung để tạo được các cuộc hỏi-trả lời đúng chuẩn cho vài tỉnh là nhiều
    Tập trung vào sự đa dạng về hình thức và nội dung


Yêu cầu cần thiết mà data fine tune cần có là gì?
    - Hỏi giá cả
    - Địa chỉ 
    - Gọi ý
    - Lịch trình 
    - So sánh



====###====
Tóm lại
Quy trình em thực hiện thử nghiệm là:
1. Tạo 100 câu hỏi-trả lời bằng gemini để xem chất lượng vấn đáp ra sao 

2. Viết script Python đọc file CSV, dùng LLM nhân bản lên thành 1000 mẫu 
(đảo ngữ, đổi từ đồng nghĩa...)

3. Xuất ra file .jsonl (để chuẩn bị training)

====###====
Code trong file fine_tune.py là thực hiện viẹc xào trộn offline, chưa phải là call api
Bằng cách:
    QUESTION_TEMPLATES = [
    "{q}",                  # Mẫu 1: Câu gốc
    "Xin hỏi, {q}",         # Mẫu 2: Lịch sự
    "Ê ad ơi, {q}",         # Mẫu 3: Thân mật
    "Tư vấn giúp mình: {q}", # Mẫu 4: Nhờ vả
    ...
]

Quy trình biến đổi diễn ra như sau:
Bước 1 - Làm sạch: Code dùng re.sub để xóa mấy cái số thứ tự thừa 
(ví dụ "1. Đà Lạt..." -> "Đà Lạt...").

Bước 2 - Xáo trộn: Nó dùng random.shuffle để đảo lộn danh sách mẫu câu, 
đảm bảo mỗi lần chạy là các mẫu khác nhau được chọn (nếu danh sách mẫu nhiều hơn 10).

Bước 3 - Lắp ghép (Loop): Nó chạy vòng lặp 10 lần (NUM_VARIANTS = 10):
Lấy mẫu: "Xin hỏi, {q}"
Lấy câu gốc: "đà lạt ăn gì ngon?" (chuyển thành chữ thường).
Ghép lại: "Xin hỏi, đà lạt ăn gì ngon?"

Bước 4 - Chuẩn hóa: Code tự động viết hoa chữ cái đầu và thêm dấu chấm hỏi ? vào cuối 
câu nếu thiếu. Kết quả: Từ 1 câu gốc, nó tạo ra một danh sách 10 câu biến 
thể khác nhau về cách xưng hô.



====###====
vì sao trong file jsonl đoạn đầu toàn là text "phân vai" thế?
    -> Khi train thì model xem mỗi dòng là một trường hợp riêng biệt. Đọc không nhớ dòng đầu
    khi đọc dòng thứ 2 
    ví dụ: "bạn là Hướng dẫn viên..", nhưng câu thoại tiếp theo không nhắc nữa
        -> thành ra quên mất vai của nó

    Do vậy việc lặp lại phân vai như thế để model hiểu cứ system prompt như thế thì phải bật chế
    độ trả lời thế nào 
